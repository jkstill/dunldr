#!/usr/bin/env perl

=head1  dunldr

unload data from an oracle database

use 'dunldr -help' for help on usage

jared still
10/24/2001

=cut

use warnings;
use strict;
use FileHandle;
use DBI;
use File::Path;
use IO::File;
use Carp;
use Data::Dumper;
# this is a bug.  Data::HexConverter must be loaded dynamically
use Data::HexConverter;
use Getopt::Long;

use Module::Load::Conditional qw(check_install);
use Module::Load;

my $hexModule = 'Data::HexConverter';
my $useHexConverter = 0;
my $hexConverterInstalled = check_install(module => $hexModule);

if (defined $hexConverterInstalled) {
	#print "Version: " . ($hexConverterInstalled->{version} // 'unknown') . "\n";
	#print "Path: " . $hexConverterInstalled->{file} . "\n";
	$useHexConverter = 1;
	autoload Data::HexConverter;
}

my %bincol = ();
my %hexcols = ();
my $dumpfileSuffix='.csv';
my $recordPrefix=q{"};
my $recordSuffix=q{"};
my $fieldDelimiter='","';
my $recordDelimiter="\n";
my $loadAsCLOB = 0;
my $loadDirect = 0;
my $getHexConverionImplemtation = 0;
my $disableHexConverter = 0;

# for sqltrace
my $sqlTrace = 0;
my $traceBindValues = 0;
my $traceWaits = 1;
my $traceId = '';

# for scp to retrive trace files
my $remoteUser = '';
my $remoteHost = '';
my $remotePath = '';
my $localPath  = '';
my $keyFile = '';

my %optctl = ();
Getopt::Long::GetOptions( \%optctl, 
	"database=s",
	"username=s",
	"password=s",
	"owner=s",
	"directory=s",
	"dateformat=s",
	"header!",
	"schemadump!",
	"longlen=i",
	"rowlimit=i",
	"table=s@",
	"show-simd!", \$getHexConverionImplemtation,
	"disable-hexconverter!", \$disableHexConverter,
	"bincol=s" => \%bincol,
	"load-as-clob!", \$loadAsCLOB,
	"load-direct!", \$loadDirect,
	"file-suffix=s" => \$dumpfileSuffix,
	"record-prefix=s" => \$recordPrefix,
	"record-suffix=s" => \$recordSuffix,
	"field-delimiter=s" => \$fieldDelimiter,
	"record-delimiter=s" => \$recordDelimiter,
	# for sql trace
	"sql-trace!"   => \$sqlTrace,
	"trace-waits!" => \$traceWaits,
	"trace-binds!" => \$traceBindValues,
	"trace-id=s"   => \$traceId,
	# for scp if needed for trace file
   'remote-user=s' => \$remoteUser,
   'remote-host=s' => \$remoteHost,
   'local-path=s'  => \$localPath,
   'key-file=s'    => \$keyFile,

	"sysdba!",
	"sysoper!",
	"z","h","help"
) or die Usage(1);

warn "Data::HexConverter is not installed - using unpack() for binary to hex conversion\n" unless $useHexConverter;

if ( $disableHexConverter ) {
	$useHexConverter = 0;
	warn "Data::HexConverter use disabled via --disable-hexconverter option\n";
}

if ( $useHexConverter && $getHexConverionImplemtation ) {
	print "Data::HexConverter::binary_to_hex_impl-> " . binary_to_hex_impl() . "\n";
	print "Data::HexConverter::hex_to_binary_impl-> " . hex_to_binary_impl() . "\n";
	exit(0);
}

for my $table ( keys %bincol ) {
	my @bincols = split(/\,/,$bincol{$table});
	$hexcols{uc($table)} = \@bincols;
}

if ( $recordPrefix eq 'NA' ) { $recordPrefix = ''; }
if ( $recordSuffix eq 'NA' ) { $recordSuffix = ''; }

#print Dumper(\%optctl);
#print Dumper(\%hexcols);
#for my $hexdumpcol ( @{$hexcols{XML_DATA}} ) {
	#print "hexdumpcol: $hexdumpcol\n";
#}
#exit;

our($db, $username, $password, $connectionMode);

$connectionMode = 0;
if ( $optctl{sysoper} ) { $connectionMode = 4 }
if ( $optctl{sysdba} ) { $connectionMode = 2 }

Usage(1) unless $optctl{database};
Usage(1) unless $optctl{username};
Usage(1) unless $optctl{password};
Usage(1) unless $optctl{owner};
$optctl{longlen} = 65535 unless $optctl{longlen};

if ( $optctl{h} || $optctl{z} || $optctl{help} ) {
	Usage(0);
}

if ( $optctl{schemadump} ) {
	$optctl{table} = ['SCHEMADUMP']; 
} else {
	Usage(1) unless $optctl{table};
}

# default hdr to off
$optctl{header} ||= 0;

#if ( $optctl{bincol} ) {
#}

$username=$optctl{username};
$password = $optctl{password};
$db = $optctl{database};


# create the working directory
unless ( $optctl{directory} ) {
	$optctl{directory} = qq{$optctl{owner}.dump};
}

# create directory path if it doesn't exist
-d $optctl{directory} || File::Path::mkpath([$optctl{directory}]);

our $dbh = DBI->connect(
	'dbi:Oracle:' . $db, 
	$username, $password, 
	{ 
		RaiseError => 1, 
		AutoCommit => 0,
		ora_session_mode => $connectionMode
	} 
	);

die "Connect to  $db failed \n" unless $dbh;

my $sqltraceObj;

if ( $sqlTrace ) {
   $sqltraceObj = DBI::Oracle::SQLTrace->new(
      DBH => $dbh,
      DEBUG => 0,
      BINDS => $traceBindValues,
      WAIT => $traceWaits,
      TRACE_ID => $traceId
   );
   $sqltraceObj->start_trace();
   warn "SQL Trace started\n";
}

$dbh->{LongReadLen} = $optctl{longlen};
$dbh->{RowCacheSize} = 100;


# set Oracle NLS date format
if ( $optctl{dateformat} ) {
	$dbh->do(qq{alter session set nls_date_format = '$optctl{dateformat}'} );
}

my $tableHash = new Tables($dbh, \%optctl, $dumpfileSuffix);

#print "tables: ", join(':', keys %{$tableHash}), "\n";
#for my $table (  keys %{$tableHash} ){
	#print "TABLE: $table  FILE: $tableHash->{$table}\n";
#}

# print console info immediately
autoflush STDOUT 1;

my $sth;

# take a dump
for my $table (  keys %{$tableHash} ){

	print "Table: $table\n";

	my $sql = qq{select * from $optctl{owner}\.$table};

	if ( $optctl{rowlimit}){
		$sql .= qq{ where rownum <= $optctl{rowlimit}};
	}

	$sth = $dbh->prepare($sql);

	my @columns = @{$sth->{NAME_uc}};
	my %colOrder = ();
	for my $el ( 0 ..$#columns ) {
		$colOrder{$columns[$el]} = $el;
	}

	my $dumpFile = $optctl{directory} . '/' . $tableHash->{$table};
	open(DUMP, "+> $dumpFile") || die "could not create file $dumpFile - $!\n";

	if ( $optctl{header} ) {
		print DUMP $recordPrefix . join($fieldDelimiter,@columns) . $recordSuffix . $recordDelimiter;
	}

	$sth->execute;

	# create the ctl and par files
	Tables->createCtl( 
		TABLE => $table, 
		COLUMNS => \@columns, 
		DUMPFILE => $tableHash->{$table},
		DIRECTORY => $optctl{directory},
		SCHEMA => $optctl{owner},
		HEXCOLS => \@{$hexcols{$table}},
		COLORDER => \%colOrder,
		RECSEP => $recordDelimiter,
		FIELDSEP => $fieldDelimiter,
		LONGLEN => $optctl{longlen},
		LOADASCLOB => $loadAsCLOB ,
		LOADDIRECT => $loadDirect
	);

	print "LOADASCLOB: $loadAsCLOB\n";

	# turn warnings off here so that warnings are not
	# reported for null columns when printed
	# comment it out to see what I mean
	no warnings;
	while ( my $ary = $sth->fetchrow_arrayref ) {
		# change column to hex if specified as binary via -bincol arg
		if ( exists $hexcols{$table} ) {
			for my $hexdumpcol ( @{$hexcols{$table}} ) {
				# use Data::HexConverter module to do the conversion as it is much faster
				if ( $useHexConverter ) {
					$ary->[$colOrder{uc($hexdumpcol)}] = uc( binary_to_hex(\$ary->[$colOrder{uc($hexdumpcol)}] ));
				} else {
					$ary->[$colOrder{uc($hexdumpcol)}] = uc(unpack("H*",$ary->[$colOrder{uc($hexdumpcol)}]));
				}
			}
		}
		print DUMP  $recordPrefix . join(qq{$fieldDelimiter},@{$ary}) . $recordSuffix . qq{$recordDelimiter};
		#print "ROW: " . q{'} . join(q{','},@{$ary}) . qq{'\n};
	}
	use warnings;
	close DUMP;
}

if ( $sqlTrace ) {
   $sqltraceObj->stop_trace();
   my $traceFile = $sqltraceObj->get_trace_file_name();
   warn "SQL Trace stopped\n";
   warn "Trace file: $traceFile\n";
	if ( $remoteUser && $remoteHost && $traceFile && $localPath ) {

		my $scp = Net::SCP->new();

		eval {
   		$scp->scp_get($remoteUser, $remoteHost, $traceFile, $localPath, $keyFile);
   		print "File copied successfully from ${remoteUser}\@${remoteHost}:${remotePath} to ${localPath}\n";
		};

		if ($@) {
			 carp "\nError during scp_get:\n $@\n\n";
		}

	} else {
		warn "To retrieve trace file via scp, use the following options:\n";
		warn " --remote-user <user> --remote-host <host> \n";
		warn " --remote-path <remote trace file path> --local-path <local path>\n";
	}
}

#$sth->finish;
$dbh->disconnect;

sub Usage {

	my ($exitCode) = @_;
	
	print q{

dunldr - data unloader for Oracle 

usage:

   dunldr --database <database> --username <userid> --password <password> \
     --directory <data unload directory> \
     --header|noheader \
     --owner <schema owner> \
     --table <table1,table2,table3,...)


   --database           database name

   --username           user to login as

   --password           password for login user

   --owner              owner of tables to dump

   --directory          directory to unload data into
                        will default to <owner>.dump 

   --dateformat         Oracle NLS date format - optional
   --header             first line is column names
   --noheader           no column names


   --table              table to dump.  may be repeated as many
                        times as necessary.

   --schemadump         dump entire schema of <owner>
                        will ignore --table settings

   --file-suffix        defaults to '.csv'

   --rowlimit           limit number of rows returned

   --longlen            if longs are in the table, set this
                        to the maximum length you want.
                        defaults to 65535

   --bincol             use to specify columns that should be dumped
                        in hex format.  columns with binary data tend
                        to cause problems in text dumps.
                        e.g. --bincol <table_name>=<column_name,column_name,...>

   --load-as-clob       load hex columns as CLOBs

   --load-direct        load binary columns with direct mode

   --record-prefix      string at beginning of record
                        default: '"' - use NA for empty string

   --record-suffix      string at end of record
                        default: '"' - use NA for empty string

   --field-delimiter    string that delimits end of field
                        default: '","'

   --record-delimiter   string that delimits end of record
                        default: "\n"

   --show-simd          show which Intel Extended Instruction set implementation of
                        Data::HexConverter is being used

   --disable-hexconverter
                        disable use of Data::HexConverter module even if installed
                        used for testing

  SQL TRACE OPTIONS:
   --sql-trace          enable SQL trace for the session
   --trace-waits        enable wait event tracing (default)
   --trace-binds        enable bind value tracing
   --trace-id           set trace file identifier (default '')

  SCP OPTIONS (to retrieve trace file if needed):
   --remote-user USER
   --remote-host HOST
   --local-path /path/to/local/destination 
   [--key-file /path/to/private/key]

   dunldr --database orcl --username system --password manager \
     --owner scott --directory scott.tables \
     --header \
     --table emp \
     --table dept \
     --table sales

   dunldr --database orcl --username system --password manager \
     --owner scott \
     --dateformat 'yyyy-mm-dd' \
     --header \
     --file--suffix '.data' \
     --schemadump \
     --bincol xml_data=payload,header,authorization \
     --bincol app_notes=text
     --record-prefix 'NA' \
     --record-suffix 'NA' \
     --field-delimiter '<EOFD>' \
     --record-delimiter '<EORD>'

   dunldr --database orcl --username system --password manager \
     --owner scott \
     --dateformat 'yyyy-mm-dd hh24:mi:ss' \
     --header \
     --file-suffix '.data' \
     --schemadump \
     --bincol xml_data=payload,header,authorization \
     --bincol app_notes=text

};

	exit ($exitCode ? $exitCode : 0);
}


package Tables;

use Data::Dumper;

sub new {

	my $pkg = shift;
	my $class = ref($pkg) || $pkg;

	my ( $dbh, $optionHash, $fileSuffix ) = @_;
	
	my $tableHash;
	if ( grep(/^SCHEMADUMP$/, @{$optionHash->{table}} ) ) {
		# get all tables of owner
		my $sql = q{
			select table_name 
			from all_tables
			where owner = ?
		};
		my $sth = $dbh->prepare($sql);
		$sth->execute(uc($optionHash->{owner}));
		my @tableArray; 
		while( my $ary = $sth->fetchrow_arrayref ) {
			push(@tableArray, $ary->[0]);
		}
		$tableHash = setTables(\@tableArray,$fileSuffix);
	} else {
		$tableHash = setTables(\@{$optionHash->{table}},$fileSuffix);
	}

	bless $tableHash, $class;
	return $tableHash;

}


=head1 setTables

  make a neat hash of the form TABLE_NAME => 'table_name.dump'
  all table names upper case, all file names lower case
  for dump file names - Perl is awesome

=cut


sub setTables {
	my ($tableArray,$fileSuffix) = @_;

	my %tables = map(
		split(/:/, $_), 
		map( 
			$_.':'.lc($_).$fileSuffix, 
			split(
				/:/,
				uc(join(':',@{$tableArray}))
			)
		)
	);

	# uncomment these lines to see it
	#use Data::Dumper;
	#print Dumper(\%tables);
	#exit;

	my $hashRef = \%tables;
	return $hashRef;
}


sub createCtl {
	my($self,%args) = @_;

	my @columns = @{$args{COLUMNS}};
	my %colOrder = %{$args{COLORDER}};

	if ( $args{HEXCOLS} ) {
		for my $hexdumpcol ( @{$args{HEXCOLS}} ) {

			my $loadLine = '';
			my $conversionFunction = '';

			if ( $args{LOADDIRECT} ) {
				$conversionFunction = '';
			} else {
				$conversionFunction = qq{ "HEXTORAW(:$columns[$colOrder{uc($hexdumpcol)}])"};
			}

			if ( $args{LOADASCLOB} ) {
				$loadLine = qq{ CHAR($args{LONGLEN}) };
			} else {
				$loadLine = qq{ CHAR($args{LONGLEN}) $conversionFunction};
			}

			$columns[$colOrder{uc($hexdumpcol)}] = 
				$columns[$colOrder{uc($hexdumpcol)}] . $loadLine
		}
	}

	my $ctlFile = $args{DIRECTORY}. '/' . lc($args{TABLE}) . '.ctl';
	my $ctlFh = new IO::File();
	$ctlFh->open("> $ctlFile") || die "cannot create file $ctlFile - $!\n";

	if ($loadDirect) {
		$ctlFh->print("OPTIONS (DIRECT=TRUE)\n");
	}

	$ctlFh->print("load data\n");
	$ctlFh->print("infile '$args{DUMPFILE}'\n");

	if ( $args{RECSEP} ne "\n" ) {
		$ctlFh->print(qq{   "str '$args{RECSEP}'"\n});
	}

	
	$ctlFh->print("into table $args{TABLE}\n");

	# fields terminated by '<EOFD>'

	if ( $args{FIELDSEP} ne '","' ) {
		$ctlFh->print(qq{fields terminated by '$args{FIELDSEP}'\n});
	} else {
		$ctlFh->print(q{fields terminated by ',' optionally enclosed by '"'}. "\n");
	}

	$ctlFh->print("(\n");
	$ctlFh->print( "\t" . join(",\n\t",@columns) . "\n");
	$ctlFh->print(")\n");
	$ctlFh->close;
	

	my $parFile = $args{DIRECTORY}. '/' . lc($args{TABLE}) . '.par';
	my $parFh = new IO::File();
	$parFh->open("> $parFile") || die "cannot create file $parFile - $!\n";
	$parFh->print("userid = $args{SCHEMA}\n");
	$parFh->print("control = " . lc($args{TABLE}) . ".ctl\n");
	$parFh->print("log = " . lc($args{TABLE}) . ".log\n");
	$parFh->print("bad = " . lc($args{TABLE}) . ".bad\n");
	$parFh->close;
	
}

BEGIN {

package DBI::Oracle::SQLTrace;

use strict;
use warnings;
use Carp;
use Data::Dumper;
$Data::Dumper::Indent=2; # 1= more compact indentation, 2=default
$Data::Dumper::Sortkeys=1; # sorted hash keys handier for consistency
$Data::Dumper::Maxrecurse=3;
$Data::Dumper::Maxdepth=3;
$Data::Dumper::Terse=0;

use Exporter qw(import);
our $VERSION=0.1;
our @EXPORT = qw(start_trace stop_trace);
our @ISA=qw(Exporter);

use constant {
   START_TRACE => 0,
   STOP_TRACE  => 1,
};

my %SQL = (
	START_TRACE => q{alter session set events '10046 trace name context forever, level  },
	STOP_TRACE  => q{alter session set events '10046 trace name context off'},
	SET_TRACE_ID => q{alter session set tracefile_identifier = '?'},
	GET_TRACE_FILE_NAME => q{select value from v$diag_info where name = 'Default Trace File'},
);

sub new {
	my $pkg = shift;
	my $class = ref($pkg) || $pkg;

	my (%args) = @_;

=head1 DESCRIPTION

  This module provides methods to start and stop SQL trace
  on an Oracle database session.

  The user must have the alter session privilege.

=cut

=head2 ARGUMENTS

 Passed as a hash:
 DBH           - database handle
 BINDS         - include bind values in trace (default 0)
 WAITS         - include wait events in trace (default 1)
 DEBUG         - debug flag (default 0)
 TRACE_ID      - value added the trace file name (default '')

=cut

	$args{SQL} = \%SQL;

	my $self = bless \%args, $class;

	if ( ! exists($self->{DEBUG}) ) { $self->{DEBUG} = 0; }
	if ( ! exists($self->{BINDS}) ) { $self->{BINDS} = 0; }
	if ( ! exists($self->{WAITS}) ) { $self->{WAITS} = 1; }

	my $trace_level = 0;
	$trace_level += 4 if ( $self->{BINDS} );
	$trace_level += 8 if ( $self->{WAITS} );
	$self->{TRACE_LEVEL} = $trace_level;

	if ( defined $self->{TRACE_ID} ) {
		print STDERR "Setting trace ID to $self->{TRACE_ID}\n" ; #if $self->{DEBUG};
		$self->set_trace_id( $self->{TRACE_ID} );
	} else {
		croak "DBI::Oracle::SQLTrace->new: DBH argument is required\n";
	}

	#print "DBI::Oracle::SQLTrace self: ", Dumper($self) ; #if $args{DEBUG};

	# one way to create a dispatch table in an object
	# this is probably the simplest and least flexible method
	# but it is one I will understand easily again when
	# working on the code at a later time
	$self->{dispatchers}[START_TRACE] = sub { $self->start_trace(); };
	$self->{dispatchers}[STOP_TRACE] = sub { $self->stopTrace(); };

	return $self;
}

sub get_trace_file_name {
	my ($self) = @_;
	my ($dbh) = $self->{DBH};
	#print Dumper($self);
	my $sth = $dbh->prepare($SQL{GET_TRACE_FILE_NAME});
	$sth->execute;
	my ($traceFile) = $sth->fetchrow_array;
	$sth->finish;
	return $traceFile;
}

sub set_trace_id {
	my ($self, $trace_id) = @_;
	my ($dbh) = $self->{DBH};
	eval {
		local $dbh->{RaiseError} = 1;
		local $dbh->{PrintError} = 0;
		$dbh->do("alter session set tracefile_identifier = '$trace_id'");
	};
	if ($@) {
		cleanup_and_croak($self, "Failed to set tracefile identifier to $trace_id: $@");
	}
	return get_trace_file_name($self);
}

sub start_trace {
	my ($self) = @_;
	warn "Starting trace with level $self->{TRACE_LEVEL}\n";
	warn "SQL: ", $self->{SQL}{START_TRACE}, "\n" ;
	my $sth = $self->{DBH}->prepare($self->{SQL}{START_TRACE} . qq{$self->{TRACE_LEVEL}'});
	$sth->execute;
	$sth->finish;
}
sub stop_trace {
	my ($self, $dbh) = @_;
	$self->{DBH}->do($self->{SQL}{STOP_TRACE});
}

sub cleanup_and_croak {
	my ($self, $msg) = @_;
	eval {
		local $dbh->{RaiseError} = 1;
		local $dbh->{PrintError} = 0;
		$self->stop_trace();
		$self->{DBH}->disconnect if $self->{DBH};
	};	
	croak $msg;
}
1;
}

BEGIN {
package Net::SCP;
use Carp;
use strict;
use warnings;

use Data::Dumper;
$Data::Dumper::Indent=2; # 1= more compact indentation, 2=default
$Data::Dumper::Sortkeys=1; # sorted hash keys handier for consistency
$Data::Dumper::Maxrecurse=3;
$Data::Dumper::Maxdepth=3;
$Data::Dumper::Terse=0;

use Exporter qw(import);
our $VERSION=0.1;
our @EXPORT = qw(scp_get);
our @ISA=qw(Exporter);

# locate the scp binary
sub locate_binary {
	my $self=shift;
	my $filename=shift;
	my $whichBinary = '';;

	# Get the PATH environment variable
	my $path = $ENV{PATH};

	my @pathDirs = split /:/, $path; # Use ';' for Windows

	foreach my $dir (@pathDirs) {
		my $fullPath = "$dir/$filename";

		# Check if the file exists at this full path
		if (-e $fullPath) {
			$whichBinary = $fullPath;
			last; # Stop searching once found
		}
	}

	unless ($whichBinary) {
    	print "File '$filename' not found in PATH.\n";
		croak "locate_binary: $filename not found in PATH";
	}

	$self->{${filename}.'_binary'}=$whichBinary;

	return $self;
}

sub new {
  my $class=shift;
  my $self={};
  $self=locate_binary($self,'scp');
  bless $self, $class;
  return $self;
}

sub scp_get {
  my ($self, $remoteUser, $remoteHost, $remotePath, $localPath,$keyFile)=@_;
  croak "scp_get: missing arguments" unless defined $remoteUser && defined $remoteHost && defined $remotePath && defined $localPath;

  my $scpCmd="$self->{scp_binary} ";
  $scpCmd .= " -B "; # batch mode, no password prompts
  $scpCmd .= " -i ${keyFile} " if defined $keyFile && $keyFile ne '';
  $scpCmd .= " ${remoteUser}\@${remoteHost}:${remotePath} ${localPath}";
  print "Executing: $scpCmd\n";
  my $result=system($scpCmd);
  if ($result != 0) {
	 croak "scp_get: scp command failed with exit code ".($result >> 8);
  }
  return 1;
}
1;
}

1;


